1)
 M. Franken and J. C. van Gemert, ‘‘Automatic Egyptian hieroglyph
recognition by retrieving images as texts,’’ in Proc. 21st ACM Int. Conf.
Multimedia, 2013, pp. 765–768.

work description

The authors conduct experiments to evaluate the recognition performance of the different image descriptors, matching schemes, and language models using the created hieroglyph dataset

problem found

Recognizing hieroglyphs from photographs presents challenges due to the lack of proper segmentation, reading order, and the degradation of symbols over time.




2)
 P. Wiesenbach and S. Riezler, ‘‘Multi-task modeling of phonographic
languages: Translating middle Egyptian hieroglyphs,’’ in Proc. 16th Int.
Conf. Spoken Lang. Transl., 2019, pp. 1–7.


The provided text appears to be a scholarly paper or research paper discussing a multi-task learning approach for translating Middle Egyptian hieroglyphs. 

work description

The text describes the multi-task learning approach, where they use multiple tasks, including hieroglyph transcription and translation, to improve the translation of hieroglyphs. The idea is to share information between these tasks to overcome the low-resource problem.

Neural Architecture: The authors detail the neural architecture used in their experiments, including encoder/decoder systems with attention mechanisms and different settings for embedding dimensions.

Multi-Task Experiments: The core of the paper, this section covers experiments in many-2-one, one-2-many, many-2-many, and "all-in" settings. The results show the impact of using transcriptions and POS tagging in multi-task learning for improving hieroglyph translation.



